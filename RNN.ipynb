{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8d6427-b409-465e-b39f-257698ccf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c4cbc6-c189-40ab-a215-595459fc218d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(\"input.txt\").read()\n",
    "\n",
    "text = text[:5000]  # training on only 5000 characters coz my gpu cant handle much :(\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5e4f15-66b0-46ea-acf5-1a8448f212d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(text))\n",
    "\n",
    "itos = {i:s for i, s in enumerate(chars)}\n",
    "\n",
    "stoi = {s:i for i, s in itos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8363cad5-f802-4096-863a-51ca90d862aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4822549-1c53-42a9-ac36-9f3ae0c9a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4dc7c71-ef10-44da-8fd9-0eb582901917",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(chars)\n",
    "hidden_size = 128\n",
    "output_size = len(chars)\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409ae3ba-2368-4dd5-ad95-84be11ce1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, output_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c06756-f8c4-427f-972c-11f25ade5541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 3.1185\n",
      "Epoch [20/100], Loss: 2.7991\n",
      "Epoch [30/100], Loss: 2.4264\n",
      "Epoch [40/100], Loss: 2.2005\n",
      "Epoch [50/100], Loss: 1.9668\n",
      "Epoch [60/100], Loss: 1.7809\n",
      "Epoch [70/100], Loss: 1.6249\n",
      "Epoch [80/100], Loss: 1.3874\n",
      "Epoch [90/100], Loss: 1.2221\n",
      "Epoch [100/100], Loss: 1.0293\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    hidden = model.init_hidden(batch_size=1)\n",
    "\n",
    "    inputs = torch.tensor([stoi[ch] for ch in text[:-1]], dtype=torch.long, device=device)\n",
    "    targets = torch.tensor([stoi[ch] for ch in text[1:]], dtype=torch.long, device=device)\n",
    "    inputs_one_hot = torch.zeros(inputs.shape[0], len(chars), device=device)\n",
    "    for i in range(inputs_one_hot.shape[0]):\n",
    "        inputs_one_hot[i][inputs[i]] = 1\n",
    "    inputs_one_hot = inputs_one_hot.unsqueeze(0)\n",
    "\n",
    "    outputs, hidden = model(inputs_one_hot, hidden)\n",
    "    loss = loss_fn(outputs.view(-1, output_size), targets.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3376c79-aef3-447f-a320-eaf0fe94ecc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gheus?\n",
      "\n",
      "Secong ur in\n",
      "noursvindsire ath sitlle, beart,owe'. \n",
      "Aal: your bedledy, the bell: iu whal splok, wo\n",
      "tieabe; the costhesito en tho ghay with or wealle ally at ie caremes ly\n",
      "se cobell: sertistly pook.\n",
      "\n",
      "Aly:\n",
      "Heve, yeacchy gaicouss malt-coms ar musp forthis bow titllin;trfcounk, ally.\n",
      "\n",
      "MENENIUS:\n",
      "Eathom artice it burathin tareihe aik nitoze':\n",
      "Ley uresty semetery god vermunto til  in citite s;rovedore beay ane thay soof lames,\n",
      "Is arveros areas, mus arveueselvenoufmo toithe piti, the dakeeety\n"
     ]
    }
   ],
   "source": [
    "start_char = 'T'\n",
    "num_chars = 500\n",
    "hidden = model.init_hidden(batch_size=1)\n",
    "input_char = start_char\n",
    "output_text = start_char\n",
    "with torch.no_grad():\n",
    "    for i in range(num_chars):\n",
    "        input_idx = torch.tensor([stoi[input_char]], dtype=torch.long, device=device)\n",
    "        input_one_hot = torch.zeros(1, 1, input_size, device=device)\n",
    "        input_one_hot.scatter_(2, input_idx.unsqueeze(1).unsqueeze(0), 1)\n",
    "\n",
    "        output, hidden = model(input_one_hot, hidden)\n",
    "        output_dist = output.squeeze().exp()\n",
    "\n",
    "        top_char_idx = torch.multinomial(output_dist, 1)[0]\n",
    "        output_char = itos[top_char_idx.item()]\n",
    "\n",
    "        output_text += output_char\n",
    "\n",
    "        input_char = output_char\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83806a-5497-4e02-8e3b-12cf318c5e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
